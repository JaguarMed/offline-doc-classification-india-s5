# üèóÔ∏è Architecture du Projet CV-NLP

## Vue d'Ensemble

Le projet suit une architecture modulaire avec 3 modules de classification compl√©mentaires + un module de fusion.

```
Image/PDF
    ‚Üì
[OCR] ‚Üí Texte
    ‚Üì
    ‚îú‚îÄ‚Üí [Text Classifier] (mDeBERTa) ‚îÄ‚îÄ‚îê
    ‚îú‚îÄ‚Üí [Vision Classifier] (ViT) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îî‚îÄ‚Üí [ORB Classifier] (motifs) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
                                        ‚Üì
                                  [Fusion Module]
                                        ‚Üì
                                  Pr√©diction Finale
```

## üìÅ Structure des Modules

### 1. Module OCR+NLP (`modules/ocr_nlp/`)

**Fichiers**:
- `ocr.py`: Extraction OCR avec cache
- `text_classifier.py`: Classifieur Transformer texte

**Fonctionnalit√©s**:
- Extraction OCR multi-langue (FR/AR)
- Cache des r√©sultats OCR (hash MD5)
- Pr√©-traitement image (grayscale, threshold)
- Classification via mDeBERTa fine-tun√©
- Nettoyage texte robuste

**API**:
```python
from modules.ocr_nlp import extract_ocr_text, TextClassifier

# OCR
text = extract_ocr_text("image.png", languages="fra+ara")

# Classification
classifier = TextClassifier("checkpoints/text")
result = classifier.predict(text)
# ‚Üí {'label': 'CIN', 'confidence': 0.95, 'probabilities': {...}}
```

### 2. Module Vision (`modules/vision/`)

**Fichiers**:
- `vision_classifier.py`: Classifieur Vision Transformer

**Fonctionnalit√©s**:
- Support Swin-Tiny et DeiT-Small
- Optimis√© pour CPU (inference_mode)
- Redimensionnement automatique (224x224)
- Normalisation standard ImageNet

**API**:
```python
from modules.vision import VisionClassifier

classifier = VisionClassifier(
    "checkpoints/vision",
    model_type="swin_tiny"
)
result = classifier.predict("image.png")
# ‚Üí {'label': 'CIN', 'confidence': 0.92, 'probabilities': {...}}
```

### 3. Module ORB (`modules/orb/`)

**Fichiers**:
- `orb_classifier.py`: Classifieur bas√© sur ORB

**Fonctionnalit√©s**:
- D√©tection de keypoints ORB
- Scores heuristiques bas√©s sur:
  - Densit√© de features
  - Ratio d'aspect
  - D√©tection de lignes (tableaux)
- Probabilit√©s normalis√©es par classe

**API**:
```python
from modules.orb import ORBClassifier

classifier = ORBClassifier()
result = classifier.predict("image.png")
# ‚Üí {'label': 'CIN', 'confidence': 0.65, 'probabilities': {...}, 'metadata': {...}}
```

### 4. Module Fusion (`modules/fusion/`)

**Fichiers**:
- `fusion.py`: Soft voting pond√©r√©

**Fonctionnalit√©s**:
- Fusion pond√©r√©e des probabilit√©s
- Poids configurables (text, vision, orb)
- Normalisation automatique
- D√©tails par module dans le r√©sultat

**API**:
```python
from modules.fusion import FusionModule

fusion = FusionModule(weight_text=0.6, weight_vision=0.3, weight_orb=0.1)
result = fusion.fuse(text_pred, vision_pred, orb_pred)
# ‚Üí {'label': 'CIN', 'confidence': 0.88, 'probabilities': {...}, 'module_details': {...}}
```

## üîÑ Pipeline d'Inf√©rence (`pipeline/inference.py`)

**Classe**: `InferencePipeline`

**Responsabilit√©s**:
- Orchestration des 3 modules
- Gestion des erreurs (fallback sur pr√©dictions neutres)
- Configuration via YAML ou param√®tres directs
- Support CPU/CUDA automatique

**Flux d'ex√©cution**:
1. Charger image/PDF
2. Extraire OCR (avec cache)
3. Pr√©dire via Text Classifier
4. Pr√©dire via Vision Classifier
5. Pr√©dire via ORB Classifier
6. Fusionner les 3 pr√©dictions
7. Retourner r√©sultat complet

**API**:
```python
from pipeline.inference import InferencePipeline

pipeline = InferencePipeline(
    config_path="config/config.yaml",
    text_checkpoint="checkpoints/text",
    vision_checkpoint="checkpoints/vision"
)

result = pipeline.predict("document.png", return_ocr_text=True, return_details=True)
# ‚Üí {
#     'prediction': {'label': 'CIN', 'confidence': 0.88, ...},
#     'ocr_text': '...',
#     'module_predictions': {...}
# }
```

## üõ†Ô∏è Outils CLI (`tools/`)

### `build_dataset.py`

**R√¥le**: Pr√©parer dataset avec OCR

**Entr√©e**: Dossier structur√© par classe
```
dataset/
‚îú‚îÄ‚îÄ CIN/
‚îÇ   ‚îú‚îÄ‚îÄ CIN_001.png
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ releve_bancaire/
‚îÇ   ‚îî‚îÄ‚îÄ ...
```

**Sortie**: CSV avec colonnes:
- `file_path`
- `label`
- `ocr_text`
- `ocr_length`

### `evaluate.py`

**R√¥le**: √âvaluer un checkpoint et g√©n√©rer artefacts

**Entr√©e**:
- Dataset (structure par classe)
- Checkpoints texte et vision

**Sortie**: Dossier `runs/<run_id>/` avec:
- `config.json`: Configuration du run
- `metrics.json`: M√©triques globales et par classe
- `predictions.csv`: Pr√©dictions d√©taill√©es
- `confusion_matrix.csv` + `.png`
- `errors/top_errors.csv`

## üñ•Ô∏è Interface Streamlit (`app/analysis_app.py`)

**Pages**:

### 1. Run Browser
- S√©lection d'un run
- KPIs (accuracy, F1, etc.)
- Confusion matrix interactive
- Table m√©triques par classe
- Distribution des confidences
- Top erreurs

### 2. Error Explorer
- Filtres: true_label, pred_label, low confidence, short OCR
- Liste d'erreurs
- D√©tails par erreur:
  - Image
  - Pr√©diction finale + breakdown
  - Texte OCR

### 3. Quick Test
- Upload image/PDF
- Pr√©diction en temps r√©el
- Breakdown par module
- Probabilit√©s compl√®tes
- Texte OCR

## üìä Format des Donn√©es

### Pr√©diction d'un Module

```python
{
    'label': 'CIN',
    'confidence': 0.95,
    'probabilities': {
        'CIN': 0.95,
        'releve_bancaire': 0.02,
        'facture_eau': 0.01,
        'facture_electricite': 0.01,
        'document_employeur': 0.01
    }
}
```

### R√©sultat du Pipeline

```python
{
    'image_path': 'path/to/image.png',
    'prediction': {
        'label': 'CIN',
        'confidence': 0.88,
        'probabilities': {...},
        'module_details': {
            'text': {'label': 'CIN', 'confidence': 0.95},
            'vision': {'label': 'CIN', 'confidence': 0.92},
            'orb': {'label': 'CIN', 'confidence': 0.65}
        }
    },
    'ocr_text': '...',
    'module_predictions': {
        'text': {...},
        'vision': {...},
        'orb': {...}
    }
}
```

## üîß Configuration (`config/config.yaml`)

**Sections**:
- `classes`: Liste des 5 classes
- `checkpoints`: Chemins des checkpoints
- `vision_model`: Type de mod√®le vision
- `fusion_weights`: Poids de fusion
- `ocr`: Configuration OCR (langues, cache)
- `orb`: Param√®tres ORB
- `inference`: Param√®tres d'inf√©rence (batch_size, threads, etc.)

## üß™ Tests (`tests/test_smoke.py`)

**Tests smoke**:
1. `test_ocr_extraction`: Extraction OCR sur une image
2. `test_text_classifier_loading`: Chargement classifieur texte
3. `test_vision_classifier_loading`: Chargement classifieur vision
4. `test_orb_classifier`: Classifieur ORB
5. `test_fusion_module`: Module de fusion
6. `test_inference_pipeline`: Pipeline complet

**Note**: Les tests skip automatiquement si les checkpoints ne sont pas disponibles.

## üöÄ Optimisations CPU

1. **Cache OCR**: Hash MD5 pour √©viter recalculs
2. **torch.inference_mode()**: Mode inf√©rence optimis√©
3. **Redimensionnement**: Images redimensionn√©es avant traitement
4. **Threads**: Configuration PyTorch pour CPU multi-thread
5. **Lazy Loading**: Modules charg√©s uniquement si checkpoints disponibles

## üì¶ D√©pendances Principales

- **PyTorch**: Mod√®les deep learning
- **Transformers**: mDeBERTa
- **Tesseract**: OCR
- **OpenCV**: Traitement images, ORB
- **Streamlit**: Interface web
- **Plotly**: Visualisations interactives
- **scikit-learn**: M√©triques d'√©valuation

## üîÑ Workflow Typique

1. **Pr√©paration** (local):
   ```bash
   python -m tools.build_dataset --input dataset/ --output data_ocr.csv
   ```

2. **Entra√Ænement** (Colab):
   - Fine-tuning mDeBERTa sur textes OCR
   - Fine-tuning ViT sur images
   - T√©l√©charger checkpoints

3. **√âvaluation** (local):
   ```bash
   python -m tools.evaluate --dataset dataset/ --text_ckpt ... --vision_ckpt ... --out runs/run_001
   ```

4. **Analyse** (local):
   ```bash
   streamlit run app/analysis_app.py
   ```

## üéØ Points d'Extension

- **Nouveaux modules**: Ajouter dans `modules/` et int√©grer dans `InferencePipeline`
- **Nouvelles m√©triques**: √âtendre `tools/evaluate.py`
- **Nouvelles visualisations**: Ajouter dans `app/analysis_app.py`
- **Support batch**: Ajouter m√©thode `predict_batch()` dans le pipeline
- **API REST**: Cr√©er wrapper Flask/FastAPI autour du pipeline










