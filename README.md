# CV-NLP: Classification de Documents Marocains

SystÃ¨me de classification de documents marocains utilisant 3 modules complÃ©mentaires:
1. **OCR + NLP**: Extraction de texte (Tesseract) + Classification Transformer (mDeBERTa fine-tunÃ©)
2. **Vision**: Classification d'images via Vision Transformer (Swin-Tiny/DeiT-Small fine-tunÃ©)
3. **ORB**: DÃ©tection de motifs visuels via ORB (Oriented FAST and Rotated BRIEF)

Fusion finale via **soft voting pondÃ©rÃ©**.

## ğŸ“‹ Classes de Documents

- `CIN`: Carte d'IdentitÃ© Nationale
- `releve_bancaire`: RelevÃ© bancaire
- `facture_eau`: Facture d'eau
- `facture_electricite`: Facture d'Ã©lectricitÃ©
- `document_employeur`: Document employeur (fiche de paie)

## ğŸš€ Installation

### PrÃ©requis

- Python 3.8+
- Tesseract OCR installÃ© sur le systÃ¨me
  - Windows: TÃ©lÃ©charger depuis [GitHub](https://github.com/UB-Mannheim/tesseract/wiki)
  - Linux: `sudo apt-get install tesseract-ocr tesseract-ocr-fra tesseract-ocr-ara`
  - macOS: `brew install tesseract tesseract-lang`

### Installation des dÃ©pendances

```bash
pip install -r requirements.txt
```

## ğŸ“ Structure du Projet

```
NLP-CV/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml          # Configuration du pipeline
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ ocr_nlp/             # Module OCR + NLP
â”‚   â”œâ”€â”€ vision/              # Module Vision
â”‚   â”œâ”€â”€ orb/                 # Module ORB
â”‚   â””â”€â”€ fusion/              # Module de fusion
â”œâ”€â”€ pipeline/
â”‚   â””â”€â”€ inference.py         # Pipeline d'infÃ©rence unifiÃ©
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ build_dataset.py     # Script pour prÃ©parer dataset avec OCR
â”‚   â””â”€â”€ evaluate.py          # Script pour Ã©valuer un checkpoint
â”œâ”€â”€ app/
â”‚   â””â”€â”€ analysis_app.py      # Interface Streamlit d'analyse
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_smoke.py        # Tests smoke
â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ text/                # Checkpoints modÃ¨les texte (Ã  placer ici aprÃ¨s entraÃ®nement Colab)
â”‚   â””â”€â”€ vision/              # Checkpoints modÃ¨les vision (Ã  placer ici aprÃ¨s entraÃ®nement Colab)
â”œâ”€â”€ runs/                    # RÃ©sultats d'Ã©valuation (gÃ©nÃ©rÃ©s automatiquement)
â”œâ”€â”€ dataset/                  # Dataset d'entraÃ®nement/test
â””â”€â”€ cache/                    # Cache OCR
```

## ğŸ”§ Configuration

Ã‰diter `config/config.yaml` pour ajuster:
- Chemins des checkpoints
- Type de modÃ¨le vision (`swin_tiny` ou `deit_small`)
- Poids de fusion
- Langues OCR
- ParamÃ¨tres d'infÃ©rence

## ğŸ“Š Utilisation

### 1. PrÃ©parer le Dataset avec OCR

```bash
python -m tools.build_dataset --input dataset/ --output data_ocr.csv --languages fra+ara
```

GÃ©nÃ¨re un CSV avec les textes OCR extraits pour chaque image.

### 2. Ã‰valuer un Checkpoint

```bash
python -m tools.evaluate \
    --dataset dataset/ \
    --text_ckpt checkpoints/text \
    --vision_ckpt checkpoints/vision \
    --out runs/run_001 \
    --config config/config.yaml \
    --vision_model swin_tiny
```

GÃ©nÃ¨re dans `runs/run_001/`:
- `config.json`: Configuration du run
- `metrics.json`: MÃ©triques (accuracy, F1, etc.)
- `predictions.csv`: PrÃ©dictions dÃ©taillÃ©es
- `confusion_matrix.csv` et `.png`: Matrice de confusion
- `errors/`: Top erreurs

### 3. Lancer l'Interface d'Analyse

```bash
streamlit run app/analysis_app.py
```

L'interface propose 3 pages:
- **Run Browser**: Explorer les runs, mÃ©triques, confusion matrix
- **Error Explorer**: Analyser les erreurs avec filtres
- **Quick Test**: Tester une image/PDF en temps rÃ©el

## ğŸ§ª Tests

```bash
pytest tests/test_smoke.py -v
```

Tests smoke pour vÃ©rifier:
- Chargement des checkpoints
- Pipeline d'infÃ©rence sur 1 image
- GÃ©nÃ©ration de runs

## ğŸ“¦ Checkpoints (Colab)

AprÃ¨s entraÃ®nement sur Colab, placer les checkpoints dans:

- `checkpoints/text/`: ModÃ¨le mDeBERTa fine-tunÃ© (doit contenir `config.json`, `pytorch_model.bin`, `tokenizer_config.json`, etc.)
- `checkpoints/vision/`: ModÃ¨le Vision Transformer fine-tunÃ© (fichier `.pth` ou `.pt`)

### Format attendu pour Text Checkpoint

```
checkpoints/text/
â”œâ”€â”€ config.json
â”œâ”€â”€ pytorch_model.bin (ou model.safetensors)
â”œâ”€â”€ tokenizer_config.json
â”œâ”€â”€ vocab.txt
â””â”€â”€ ...
```

### Format attendu pour Vision Checkpoint

Fichier `.pth` ou `.pt` contenant le `state_dict` du modÃ¨le fine-tunÃ©.

## ğŸ¯ Pipeline d'InfÃ©rence

Le pipeline suit cette logique:

1. **OCR**: Extraction de texte depuis l'image/PDF (avec cache)
2. **Text Module**: Classification du texte via mDeBERTa
3. **Vision Module**: Classification de l'image via ViT
4. **ORB Module**: DÃ©tection de motifs visuels
5. **Fusion**: Soft voting pondÃ©rÃ© des 3 modules
6. **RÃ©sultat**: Label final + confidence + dÃ©tails par module

## ğŸ” Optimisations CPU

- `torch.inference_mode()` pour l'infÃ©rence
- Cache OCR pour Ã©viter les recalculs
- Redimensionnement d'images optimisÃ©
- Threads configurÃ©s pour PyTorch

## ğŸ“ Notes

- L'entraÃ®nement se fait sur Colab (Optuna, fine-tuning)
- Cette interface sert uniquement Ã  l'**analyse** et au **test** (pas de tuning)
- Les modÃ¨les doivent Ãªtre fine-tunÃ©s en 5 classes avant utilisation

## ğŸ› DÃ©pannage

### Erreur Tesseract

VÃ©rifier que Tesseract est installÃ© et dans le PATH:
```bash
tesseract --version
```

### Erreur PDF

Installer `poppler` pour `pdf2image`:
- Windows: TÃ©lÃ©charger depuis [poppler-windows](https://github.com/oschwartz10612/poppler-windows/releases)
- Linux: `sudo apt-get install poppler-utils`
- macOS: `brew install poppler`

### Erreur Checkpoint

VÃ©rifier que les checkpoints sont bien placÃ©s dans `checkpoints/text/` et `checkpoints/vision/`.

## ğŸ“„ Licence

Projet interne - Classification de documents marocains.









