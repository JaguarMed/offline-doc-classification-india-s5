# ğŸ“‹ Commandes d'ExÃ©cution

## ğŸš€ Commandes Principales

### 1. PrÃ©parer le Dataset avec OCR

```bash
python -m tools.build_dataset --input dataset/ --output data_ocr.csv --languages fra+ara
```

**Description**: Extrait le texte OCR de toutes les images du dataset et gÃ©nÃ¨re un CSV.

**Options**:
- `--input`: Dossier contenant les sous-dossiers par classe (CIN/, releve_bancaire/, etc.)
- `--output`: Fichier CSV de sortie
- `--languages`: Langues OCR (dÃ©faut: "fra+ara")

**Exemple de sortie**:
```
Traitement de la classe: CIN
  CIN: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:02<00:00,  2.1it/s]
...

Dataset crÃ©Ã©: data_ocr.csv
Total: 25 fichiers
Par classe:
CIN                     5
releve_bancaire         5
...
```

---

### 2. Ã‰valuer un Checkpoint

```bash
python -m tools.evaluate \
    --dataset dataset/ \
    --text_ckpt checkpoints/text \
    --vision_ckpt checkpoints/vision \
    --out runs/run_001 \
    --config config/config.yaml \
    --vision_model swin_tiny
```

**Description**: Ã‰value un checkpoint sur le dataset et gÃ©nÃ¨re les artefacts d'analyse.

**Options**:
- `--dataset`: Dossier dataset (structure par classe)
- `--text_ckpt`: Chemin vers checkpoint texte (mDeBERTa fine-tunÃ©)
- `--vision_ckpt`: Chemin vers checkpoint vision (ViT fine-tunÃ©)
- `--out`: Dossier de sortie (ex: `runs/run_001`)
- `--config`: Chemin vers config.yaml (optionnel)
- `--vision_model`: Type de modÃ¨le vision (`swin_tiny` ou `deit_small`)

**Structure de sortie** (`runs/run_001/`):
```
runs/run_001/
â”œâ”€â”€ config.json              # Configuration du run
â”œâ”€â”€ metrics.json             # MÃ©triques (accuracy, F1, etc.)
â”œâ”€â”€ predictions.csv          # PrÃ©dictions dÃ©taillÃ©es
â”œâ”€â”€ confusion_matrix.csv     # Matrice de confusion (CSV)
â”œâ”€â”€ confusion_matrix.png     # Matrice de confusion (image)
â””â”€â”€ errors/
    â””â”€â”€ top_errors.csv       # Top 20 erreurs
```

**Exemple de sortie**:
```
Ã‰valuation classe: CIN
  CIN: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:15<00:00,  3.2s/it]
...

Ã‰valuation terminÃ©e!
Accuracy: 0.9200
Macro F1: 0.9156
Weighted F1: 0.9201

RÃ©sultats sauvegardÃ©s dans: runs/run_001
```

---

### 3. Lancer l'Interface d'Analyse (Streamlit)

```bash
streamlit run app/analysis_app.py
```

**Description**: Lance l'interface web d'analyse et de test.

**Pages disponibles**:
1. **Run Browser**: Explorer les runs, mÃ©triques, confusion matrix
2. **Error Explorer**: Analyser les erreurs avec filtres avancÃ©s
3. **Quick Test**: Tester une image/PDF en temps rÃ©el

**AccÃ¨s**: Ouvrir `http://localhost:8501` dans le navigateur

---

## ğŸ§ª Tests

### Lancer les Tests Smoke

```bash
pytest tests/test_smoke.py -v
```

**Tests effectuÃ©s**:
- Extraction OCR
- Chargement classifieur texte
- Chargement classifieur vision
- Classifieur ORB
- Module de fusion
- Pipeline d'infÃ©rence complet

**Note**: Les tests skip automatiquement si les checkpoints ne sont pas disponibles.

---

## ğŸ“¦ Placement des Checkpoints (aprÃ¨s entraÃ®nement Colab)

### Checkpoint Texte (mDeBERTa)

Placer dans `checkpoints/text/`:

```
checkpoints/text/
â”œâ”€â”€ config.json
â”œâ”€â”€ pytorch_model.bin          # ou model.safetensors
â”œâ”€â”€ tokenizer_config.json
â”œâ”€â”€ vocab.txt
â”œâ”€â”€ special_tokens_map.json
â””â”€â”€ ...
```

**Format**: ModÃ¨le HuggingFace Transformers standard (AutoModelForSequenceClassification)

### Checkpoint Vision (ViT)

Placer dans `checkpoints/vision/`:

```
checkpoints/vision/
â””â”€â”€ model.pth                  # ou model.pt
```

**Format**: Fichier PyTorch avec `state_dict` du modÃ¨le fine-tunÃ©.

**Structure attendue du checkpoint**:
```python
{
    'model_state_dict': {...},  # ou 'state_dict': {...}
    # ou directement le state_dict
}
```

---

## ğŸ”§ Configuration

### Ã‰diter `config/config.yaml`

```yaml
# Chemins des checkpoints
checkpoints:
  text: "./checkpoints/text"
  vision: "./checkpoints/vision"

# Type de modÃ¨le vision
vision_model: "swin_tiny"  # ou "deit_small"

# Poids de fusion
fusion_weights:
  text: 0.6
  vision: 0.3
  orb: 0.1

# Langues OCR
ocr:
  languages: "fra+ara"
  cache_dir: "./cache/ocr"
```

---

## ğŸ› DÃ©pannage

### Erreur: "Tesseract not found"

**Solution**: Installer Tesseract OCR
- Windows: [TÃ©lÃ©charger](https://github.com/UB-Mannheim/tesseract/wiki)
- Linux: `sudo apt-get install tesseract-ocr tesseract-ocr-fra tesseract-ocr-ara`
- macOS: `brew install tesseract tesseract-lang`

### Erreur: "poppler not found" (pour PDF)

**Solution**: Installer Poppler
- Windows: [TÃ©lÃ©charger](https://github.com/oschwartz10612/poppler-windows/releases)
- Linux: `sudo apt-get install poppler-utils`
- macOS: `brew install poppler`

### Erreur: "Checkpoint not found"

**VÃ©rifier**:
1. Les checkpoints sont bien dans `checkpoints/text/` et `checkpoints/vision/`
2. Les chemins dans `config/config.yaml` sont corrects
3. Les fichiers checkpoint sont complets (pas de corruption)

### Erreur: "CUDA out of memory"

**Solution**: Le pipeline utilise automatiquement CPU si CUDA n'est pas disponible. Pour forcer CPU:
```python
pipeline = InferencePipeline(..., device='cpu')
```

---

## ğŸ“Š Exemple de Workflow Complet

```bash
# 1. PrÃ©parer dataset avec OCR
python -m tools.build_dataset --input dataset/ --output data_ocr.csv

# 2. (Sur Colab) EntraÃ®ner les modÃ¨les et tÃ©lÃ©charger les checkpoints
#    â†’ Placer dans checkpoints/text/ et checkpoints/vision/

# 3. Ã‰valuer le checkpoint
python -m tools.evaluate \
    --dataset dataset/ \
    --text_ckpt checkpoints/text \
    --vision_ckpt checkpoints/vision \
    --out runs/run_001

# 4. Lancer l'interface d'analyse
streamlit run app/analysis_app.py

# 5. Dans l'interface:
#    - Run Browser â†’ SÃ©lectionner "run_001"
#    - Explorer mÃ©triques, confusion matrix, erreurs
#    - Quick Test â†’ Tester une nouvelle image
```

---

## ğŸ’¡ Astuces

- **Cache OCR**: Les rÃ©sultats OCR sont mis en cache dans `cache/ocr/` pour Ã©viter les recalculs
- **Optimisation CPU**: Le pipeline utilise `torch.inference_mode()` pour optimiser l'infÃ©rence
- **Threads**: Configurer `num_threads` dans `config.yaml` pour optimiser PyTorch sur CPU
- **Batch Processing**: Pour traiter plusieurs images, utiliser le pipeline dans une boucle (pas de batch processing intÃ©grÃ© pour l'instant)







